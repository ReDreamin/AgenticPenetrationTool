# WuTong（梧桐）智能渗透测试工具项目报告

## 一、背景简介/问题描述

### 1.1 实验介绍

#### 问题描述

传统渗透测试工作需要安全工程师熟练掌握大量安全工具（如 Nmap、SQLMap、Burp Suite 等）的使用方法和复杂的命令行参数。测试人员需要记忆各种工具的语法，手动分析扫描结果，并根据经验判断下一步的测试方向。这种方式存在以下问题：

1. **学习成本高**：新手需要花费大量时间学习各类工具的使用
2. **操作繁琐**：需要在多个工具之间切换，手动输入复杂命令
3. **效率低下**：人工分析结果并决策下一步行动耗时较长
4. **经验依赖强**：测试质量高度依赖测试人员的个人经验

#### 研究现状分析

当前业界主要的自动化渗透测试方案包括：

1. **传统自动化扫描器**（如 AWVS、Nessus）：功能强大但缺乏智能决策能力，只能执行预设的扫描策略
2. **脚本化工具集成**：通过脚本串联多个工具，但灵活性差，难以应对复杂场景
3. **AI 辅助安全测试**：近年来出现的基于机器学习的漏洞检测方案，但多局限于特定漏洞类型

随着大语言模型（LLM）技术的快速发展，利用 LLM 的自然语言理解和推理能力来辅助渗透测试成为可能。

#### 拟采用的方法

本项目设计并实现了 WuTong（梧桐）——一个基于大语言模型驱动的智能渗透测试工具。核心思路是：

1. **自然语言交互**：用户通过自然语言描述测试目标和需求
2. **LLM 智能编排**：利用 Claude/GPT 等大模型进行任务理解、分解和规划
3. **工具自动调度**：LLM 根据当前状态智能选择和调用渗透测试工具
4. **结果分析与决策**：LLM 分析工具返回结果，动态调整测试策略

### 1.2 实验准备

#### 实验环境介绍

| 项目 | 配置 |
|------|------|
| 操作系统 | Windows 10/11 或 Linux |
| Python 版本 | Python 3.9+ |
| LLM 服务 | Anthropic Claude / OpenAI GPT |
| 主要依赖库 | anthropic, openai, aiohttp, httpx, rich |
| 测试靶机 | DVWA, SQLi-labs 等 |

#### 依赖安装

```bash
pip install anthropic openai aiohttp httpx rich
```

#### 环境变量配置

```bash
export ANTHROPIC_API_KEY="your-anthropic-api-key"
export OPENAI_API_KEY="your-openai-api-key"
export LLM_PROVIDER="anthropic"  # 或 "openai"
```

### 1.3 实验详细设计与实现

#### 1.3.1 数据准备

##### 数据收集

本项目的"数据"主要包括以下几类：

1. **渗透测试工具定义数据**：每个工具的名称、描述、参数模式（JSON Schema）
2. **Payload 字典**：SQL 注入、XSS、LFI 等漏洞的测试载荷
3. **目录爆破字典**：常见的 Web 目录和文件名
4. **服务识别特征**：常见端口与服务的映射关系、Banner 识别规则

##### 存储格式与目录结构

```
WuTong/
├── main.py                     # CLI 入口
├── config.py                   # 配置文件（含 Payload 字典）
├── requirements.txt            # 项目依赖
├── core/
│   ├── orchestrator.py         # LLM 编排器
│   ├── llm_client.py           # LLM 客户端抽象层
│   ├── task_manager.py         # 任务管理器
│   └── reporter.py             # 报告生成器
├── mcp_server/
│   ├── server.py               # MCP 工具服务器
│   └── tools/
│       ├── http_tools.py       # HTTP 请求工具
│       ├── scan_tools.py       # 扫描工具
│       ├── exploit_tools.py    # 漏洞利用工具
│       └── utils_tools.py      # 辅助工具
├── prompts/
│   └── system_prompt.py        # 系统提示词
└── vendor/
    └── sqlmap/                 # 集成的 sqlmap 工具
```

##### 预处理介绍

1. **工具注册预处理**：启动时自动注册所有渗透测试工具，生成符合 LLM Tool Use 规范的工具定义
2. **Payload 加载**：从 config.py 加载预定义的测试载荷
3. **系统提示词构建**：根据任务类型动态生成系统提示词

#### 1.3.2 实验步骤

##### 实验流程介绍

渗透测试流程分为五个阶段：

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  信息收集   │ -> │  漏洞检测   │ -> │  漏洞利用   │ -> │  后渗透     │ -> │  报告生成   │
│   (Recon)   │    │(VulnDetect) │    │(Exploitation)│   │(PostExploit)│    │ (Reporting) │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
```

1. **信息收集阶段**：端口扫描、服务识别、目录爆破、子域名枚举
2. **漏洞检测阶段**：SQL 注入检测、XSS 检测、文件包含检测、命令注入检测
3. **漏洞利用阶段**：使用 SQLMap 进行自动化利用、Payload 生成
4. **后渗透阶段**：数据导出、权限分析
5. **报告生成阶段**：自动生成 Markdown/JSON 格式报告

##### 性能指标介绍

| 指标 | 说明 |
|------|------|
| 漏洞发现率 | 成功检测出的漏洞数量/实际存在漏洞数量 |
| 误报率 | 误报漏洞数量/报告漏洞总数 |
| 测试完成时间 | 完成一次完整渗透测试所需时间 |
| 工具调用效率 | LLM 正确选择工具的比率 |

##### 对比方法介绍

与传统手工渗透测试对比：

| 对比项 | 传统方式 | WuTong |
|--------|----------|--------|
| 交互方式 | 命令行输入 | 自然语言 |
| 任务规划 | 人工决策 | AI 自动规划 |
| 工具调用 | 手动执行 | 自动调度 |
| 结果分析 | 人工分析 | AI 辅助分析 |

---

## 二、算法介绍

### 核心算法思路

WuTong 的核心是基于 **LLM Tool Use（函数调用）** 的智能编排算法。整体思路如下：

1. **任务理解**：将用户的自然语言指令转化为结构化的渗透测试任务
2. **状态感知**：维护当前任务的状态信息（已发现端口、路径、漏洞等）
3. **决策推理**：LLM 根据当前状态和目标，决定下一步调用哪个工具
4. **工具执行**：执行选定的工具并获取结果
5. **结果融合**：将工具结果整合到任务状态中
6. **循环迭代**：重复 3-5 步直到任务完成

### 算法流程图

```
                        ┌─────────────────┐
                        │   用户输入      │
                        │ (自然语言指令)  │
                        └────────┬────────┘
                                 │
                                 ▼
                        ┌─────────────────┐
                        │  系统提示词 +   │
                        │  任务上下文     │
                        └────────┬────────┘
                                 │
          ┌──────────────────────┼──────────────────────┐
          │                      ▼                      │
          │             ┌─────────────────┐             │
          │             │   LLM 推理      │             │
          │             │ (Claude/GPT)    │             │
          │             └────────┬────────┘             │
          │                      │                      │
          │         ┌────────────┴────────────┐         │
          │         ▼                         ▼         │
          │  ┌─────────────┐          ┌─────────────┐   │
          │  │ 文本响应    │          │ 工具调用    │   │
          │  │ (分析结果)  │          │ (Tool Use)  │   │
          │  └──────┬──────┘          └──────┬──────┘   │
          │         │                        │          │
          │         ▼                        ▼          │
          │  ┌─────────────┐          ┌─────────────┐   │
          │  │ 输出给用户  │          │ 执行工具    │   │
          │  └─────────────┘          └──────┬──────┘   │
          │                                  │          │
          │                                  ▼          │
          │                          ┌─────────────┐    │
          │                          │ 返回结果    │    │
          │                          └──────┬──────┘    │
          │                                 │           │
          └─────────────────────────────────┘           │
                        (循环直到任务完成)
```

### 模型架构说明

系统采用三层架构设计：

```
┌─────────────────────────────────────────────────────────┐
│                    命令行交互层 (CLI)                    │
│   - 用户输入解析        - 命令路由                       │
│   - 结果展示            - 会话管理                       │
└─────────────────────────────────────────────────────────┘
                            │
┌─────────────────────────────────────────────────────────┐
│                   LLM 编排层 (Orchestrator)              │
│   - 自然语言理解          - 任务分解与规划                │
│   - 工具调度              - 结果分析与决策                │
│   - 对话历史管理          - 会话持久化                    │
└─────────────────────────────────────────────────────────┘
                            │
┌─────────────────────────────────────────────────────────┐
│                     MCP Tool 层                         │
│  ┌──────────┐ ┌──────────┐ ┌──────────┐ ┌──────────┐   │
│  │ HTTP工具  │ │ 扫描工具  │ │ 漏洞利用  │ │ 辅助工具  │   │
│  └──────────┘ └──────────┘ └──────────┘ └──────────┘   │
└─────────────────────────────────────────────────────────┘
```

---

## 三、算法实现

### 3.1 核心算法实现

#### 代码片段1：LLM 编排器核心循环

LLM 编排器是系统的核心，负责与 LLM API 交互并调度工具执行。

```python
# core/orchestrator.py - Orchestrator 类的核心方法 run_task
async def run_task(
    self,
    target: str,
    task_type: str = "full",
    user_message: Optional[str] = None
) -> Dict[str, Any]:
    """
    运行渗透测试任务
    Args:
        target: 目标地址
        task_type: 任务类型 (full/recon/vuln_scan/exploit)
        user_message: 用户自定义指令
    Returns:
        任务结果
    """
    # 创建任务
    task = self.task_manager.create_task(target, task_type)
    self.task_manager.start_task(task.task_id)

    # 准备初始消息
    if user_message:
        initial_message = user_message
    else:
        initial_message = get_task_prompt(target, task_type)

    # 初始化对话历史
    messages = [{"role": "user", "content": initial_message}]
    task.messages = messages.copy()

    try:
        # 主循环：LLM 推理 -> 工具调用 -> 结果处理
        while True:
            # 调用 LLM API
            response = await self._call_llm(messages)
            if not response:
                break

            # 处理响应
            serialized_content = self._serialize_response_content(response.content)
            assistant_message = {"role": "assistant", "content": serialized_content}
            messages.append(assistant_message)

            # 检查是否有工具调用
            tool_calls = [block for block in response.content
                         if isinstance(block, ToolCall)]

            if not tool_calls:
                # 没有工具调用，输出文本响应
                text_blocks = [block for block in response.content
                              if isinstance(block, TextBlock)]
                if text_blocks:
                    final_text = text_blocks[0].text
                    self._print_panel(Markdown(final_text), title="AI 分析")
                if response.stop_reason == "end_turn":
                    break
                continue

            # 执行工具调用
            tool_results = []
            for tool_call in tool_calls:
                tool_name = tool_call.name
                tool_input = tool_call.input

                # 执行工具
                start_time = time.time()
                result = await self.tool_server.execute_tool(tool_name, tool_input)
                duration = time.time() - start_time

                # 记录工具调用
                self.task_manager.add_tool_call(
                    task.task_id, tool_name, tool_input, result, duration
                )

                # 准备工具结果
                result_json = json.dumps(result, ensure_ascii=False)
                tool_results.append(
                    self.client.format_tool_result(tool_call.id, result_json)
                )

            # 添加工具结果到消息历史
            messages.append({"role": "user", "content": tool_results})

    except KeyboardInterrupt:
        self._print("[yellow]任务被用户中断[/yellow]")

    # 完成任务
    self.task_manager.complete_task(task.task_id)
    return self.task_manager.export_task(task.task_id)
```

#### 代码片段2：MCP 工具服务器 - 工具注册与执行

```python
# mcp_server/server.py - MCPToolServer 类
class MCPToolServer:
    """MCP 工具服务器 - 管理所有渗透测试工具"""

    def __init__(self):
        self.http_tools = HttpTools()
        self.scan_tools = ScanTools()
        self.exploit_tools = ExploitTools()
        self.utils_tools = UtilsTools()
        self.tools: Dict[str, ToolDefinition] = {}
        self._register_all_tools()

    def _register_tool(
        self,
        name: str,
        description: str,
        parameters: Dict[str, Any],
        handler: Callable,
        category: str = "general"
    ):
        """注册工具 - 将工具封装为可被 LLM 调用的格式"""
        self.tools[name] = ToolDefinition(
            name=name,
            description=description,
            parameters=parameters,
            handler=handler,
            category=category
        )

    def get_tools_for_claude(self) -> List[Dict[str, Any]]:
        """获取符合 LLM Tool Use 规范的工具定义"""
        claude_tools = []
        for tool in self.tools.values():
            claude_tools.append({
                "name": tool.name,
                "description": tool.description,
                "input_schema": tool.parameters
            })
        return claude_tools

    async def execute_tool(self, name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """执行工具"""
        if name not in self.tools:
            return {"success": False, "error": f"Unknown tool: {name}"}

        tool = self.tools[name]
        try:
            result = await tool.handler(**arguments)
            return result
        except Exception as e:
            return {"success": False, "error": f"Tool execution failed: {str(e)}"}
```

#### 代码片段3：SQL 注入检测工具实现

```python
# mcp_server/tools/exploit_tools.py - SQL 注入检测
async def sql_injection_test(
    self,
    url: str,
    method: str = "GET",
    params: Optional[Dict[str, str]] = None,
    data: Optional[Dict[str, str]] = None,
    payloads: Optional[List[str]] = None
) -> Dict[str, Any]:
    """SQL 注入检测"""
    if payloads is None:
        payloads = config.SQL_PAYLOADS

    vulnerabilities = []
    test_params = params or {}
    test_data = data or {}

    # SQL 错误特征正则表达式
    sql_errors = [
        r"SQL syntax.*?MySQL",
        r"Warning.*?\Wmysqli?_",
        r"MySQLSyntaxErrorException",
        r"PostgreSQL.*?ERROR",
        r"ORA-[0-9]{5}",
        # ... 更多特征
    ]

    async def test_param(param_name: str, original_value: str, is_post: bool = False):
        results = []
        for payload in payloads:
            test_value = f"{original_value}{payload}"

            if is_post:
                modified_data = {**test_data, param_name: test_value}
                result = await self._make_request(url, "POST", data=modified_data)
            else:
                modified_params = {**test_params, param_name: test_value}
                result = await self._make_request(url, "GET", params=modified_params)

            if not result.get("success"):
                continue

            body = result.get("body", "")

            # 检查 SQL 错误特征
            for error_pattern in sql_errors:
                if re.search(error_pattern, body, re.IGNORECASE):
                    results.append({
                        "param": param_name,
                        "payload": payload,
                        "type": "error_based",
                        "evidence": re.search(error_pattern, body, re.IGNORECASE).group()[:100],
                        "method": "POST" if is_post else "GET"
                    })
                    break
        return results

    # 测试所有参数
    for param_name, value in test_params.items():
        vuln_results = await test_param(param_name, value, is_post=False)
        vulnerabilities.extend(vuln_results)

    for param_name, value in test_data.items():
        vuln_results = await test_param(param_name, value, is_post=True)
        vulnerabilities.extend(vuln_results)

    return {
        "success": True,
        "url": url,
        "vulnerable": len(vulnerabilities) > 0,
        "vulnerability_count": len(vulnerabilities),
        "vulnerabilities": vulnerabilities
    }
```

#### 代码片段4：LLM 客户端抽象层

```python
# core/llm_client.py - 支持多服务商的客户端抽象
class BaseLLMClient(ABC):
    """LLM 客户端基类 - 定义统一接口"""

    @abstractmethod
    async def create_message(
        self,
        messages: List[Dict[str, Any]],
        system: str,
        tools: List[Dict[str, Any]],
        max_tokens: int = 4096
    ) -> Optional[LLMResponse]:
        """创建消息（调用 LLM API）"""
        pass

    @abstractmethod
    def format_tool_result(self, tool_call_id: str, result: str) -> Dict[str, Any]:
        """格式化工具调用结果"""
        pass


class AnthropicClient(BaseLLMClient):
    """Anthropic (Claude) 客户端实现"""

    async def create_message(self, messages, system, tools, max_tokens=4096):
        response = await self.client.messages.create(
            model=self.model,
            max_tokens=max_tokens,
            system=system,
            tools=tools,
            messages=messages
        )
        # 转换为统一格式 LLMResponse
        content = []
        for block in response.content:
            if block.type == "text":
                content.append(TextBlock(type="text", text=block.text))
            elif block.type == "tool_use":
                content.append(ToolCall(id=block.id, name=block.name, input=block.input))

        return LLMResponse(
            content=content,
            stop_reason=response.stop_reason,
            model=response.model,
            usage={"input_tokens": response.usage.input_tokens,
                   "output_tokens": response.usage.output_tokens}
        )


class OpenAIClient(BaseLLMClient):
    """OpenAI 客户端实现"""
    # 类似实现，支持 GPT 系列模型


def create_llm_client(provider: str, api_key: str, ...) -> BaseLLMClient:
    """工厂函数：根据服务商创建对应客户端"""
    if provider == "anthropic":
        return AnthropicClient(...)
    elif provider == "openai":
        return OpenAIClient(...)
```

#### 代码片段5：端口扫描工具实现

```python
# mcp_server/tools/scan_tools.py - 端口扫描
async def port_scan(
    self,
    target: str,
    ports: Optional[str] = None,
    scan_type: str = "tcp",
    timeout: int = 1
) -> Dict[str, Any]:
    """端口扫描"""
    if ports is None:
        ports = config.DEFAULT_PORTS

    port_list = self._parse_ports(ports)
    open_ports = []

    async def check_port(port: int) -> Optional[Dict[str, Any]]:
        try:
            if scan_type == "tcp":
                reader, writer = await asyncio.wait_for(
                    asyncio.open_connection(target, port),
                    timeout=timeout
                )
                writer.close()
                await writer.wait_closed()

                # 尝试获取 banner
                banner = await self._grab_port_banner(target, port)
                service = self._guess_service(port, banner)

                return {
                    "port": port,
                    "state": "open",
                    "protocol": "tcp",
                    "service": service,
                    "banner": banner[:200] if banner else None
                }
        except (asyncio.TimeoutError, ConnectionRefusedError, OSError):
            return None

    # 并发扫描（使用信号量控制并发数）
    semaphore = asyncio.Semaphore(100)

    async def bounded_check(port: int):
        async with semaphore:
            return await check_port(port)

    tasks = [bounded_check(port) for port in port_list]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    for result in results:
        if isinstance(result, dict) and result is not None:
            open_ports.append(result)

    open_ports.sort(key=lambda x: x["port"])

    return {
        "success": True,
        "target": target,
        "scanned_ports": len(port_list),
        "open_ports_count": len(open_ports),
        "open_ports": open_ports
    }
```

### 3.2 算法实验结果展示

#### 测试场景：DVWA 靶机渗透测试

**测试目标**：DVWA（Damn Vulnerable Web Application）靶机

**测试指令**：
```
WuTong> 对 192.168.244.134 进行完整渗透测试
```

#### 信息收集阶段结果

| 端口 | 协议 | 服务 | Banner |
|------|------|------|--------|
| 22 | TCP | SSH | OpenSSH 7.9 |
| 80 | TCP | HTTP | Apache/2.4.38 |
| 3306 | TCP | MySQL | MySQL 5.7 |

#### 漏洞检测结果

| 漏洞类型 | 严重程度 | URL | 参数 |
|----------|----------|-----|------|
| SQL Injection | Critical | /vulnerabilities/sqli/ | id |
| XSS (Reflected) | Medium | /vulnerabilities/xss_r/ | name |
| Command Injection | Critical | /vulnerabilities/exec/ | ip |
| LFI | High | /vulnerabilities/fi/ | page |

#### 工具调用统计

| 工具名称 | 调用次数 | 成功率 |
|----------|----------|--------|
| port_scan | 1 | 100% |
| dir_bruteforce | 1 | 100% |
| sql_injection_test | 3 | 100% |
| xss_test | 2 | 100% |
| sqlmap_scan | 1 | 100% |

#### 性能指标

| 指标 | 数值 |
|------|------|
| 总测试时间 | 约 5 分钟 |
| 漏洞发现率 | 100% (4/4) |
| 误报率 | 0% |
| 工具调用总次数 | 12 次 |

---

## 四、讨论及结论

### 1. 优缺点分析

#### 优点

1. **自然语言交互**：大幅降低使用门槛，无需记忆复杂命令
2. **智能决策**：LLM 能够根据当前状态自动规划测试路径
3. **工具集成**：统一管理多种渗透测试工具，实现自动调度
4. **可扩展性**：采用模块化设计，易于添加新工具
5. **多模型支持**：同时支持 Anthropic Claude 和 OpenAI GPT
6. **报告自动生成**：自动生成结构化的测试报告

#### 缺点

1. **API 依赖**：需要依赖外部 LLM API，存在网络和成本限制
2. **响应延迟**：LLM 推理时间导致整体测试时间较长
3. **工具覆盖有限**：目前集成的工具种类有限，需要持续扩展
4. **复杂场景处理**：对于非常复杂的渗透场景，AI 决策可能不够精确
5. **安全风险**：需要妥善处理 API Key 和敏感数据

### 2. 总结与思考

本项目成功实现了一个基于大语言模型的智能渗透测试工具 WuTong。通过将 LLM 的自然语言理解和推理能力与传统安全工具相结合，实现了以下目标：

1. **降低使用门槛**：用户可以通过自然语言描述测试需求，无需熟悉各种工具的命令行语法
2. **提升测试效率**：LLM 能够自动分析结果并规划下一步行动，减少人工决策时间
3. **标准化测试流程**：通过预定义的任务阶段和工具集，确保测试的完整性

**未来改进方向**：

1. 集成更多渗透测试工具（如 Metasploit、Burp Suite 等）
2. 支持本地部署的开源 LLM（如 LLaMA）以降低成本
3. 增加更细粒度的权限控制和审计日志
4. 开发图形化用户界面
5. 支持多目标并行测试

---

## 五、参考文献

[1] Anthropic. Claude API Documentation. https://docs.anthropic.com/

[2] OpenAI. Function Calling Guide. https://platform.openai.com/docs/guides/function-calling

[3] OWASP. Testing Guide v4. https://owasp.org/www-project-web-security-testing-guide/

[4] SQLMap. Automatic SQL injection and database takeover tool. https://sqlmap.org/

[5] Nmap. Network exploration tool and security scanner. https://nmap.org/

[6] DVWA. Damn Vulnerable Web Application. https://github.com/digininja/DVWA

---
